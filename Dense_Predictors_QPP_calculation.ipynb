{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17609d47-befe-428b-a6fc-19a9d42bf1fc",
   "metadata": {},
   "source": [
    "# Coherence-based QPP Predictors for Dense Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71393a3-d3ef-47e3-a4e0-5bacbb44df62",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how we obtain our results for the QPP Dense Coherence-based predictors, namely pairRatio and A-pairRatio. Below, we provide some example form of retrieval results for a given retrieval method. However, the reader can produce their own results files and replace the corresponding csv files in the arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab1f0c-4f98-46e0-aca3-fc9e374ae52d",
   "metadata": {},
   "source": [
    "First, we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7487acfb-ac79-41e8-a762-a1f5c952a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/genir/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr,kendalltau\n",
    "from scipy.spatial.distance import cdist,cosine\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy import spatial\n",
    "from math import sqrt, log\n",
    "from pyterrier.measures import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076672b5-bf1c-4774-aa1f-0c3c11dc6859",
   "metadata": {},
   "source": [
    "Make sure you have installed pyterrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd745f5-0263-4c49-a3c1-2e372cb21cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade git+https://github.com/terrier-org/pyterrier.git \n",
    "import pyterrier as pt\n",
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da7cb14-1a6b-4a40-9f5e-895463c17464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##make sure you have the laterst version of pyterrier\n",
    "pt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ab7ba-f6c7-40a2-b084-14463887ae38",
   "metadata": {},
   "source": [
    "To use the dense retrieval results for TCT-ColBERT and ANCE, please make sure to find the corresponding index from http://data.terrier.org. Now, you can load the per query results for TREC DL 2019 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6c327ae-2725-4dcb-82c0-6b87ebb7ef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>qid</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compose(TctColBert('castorini/tct_colbert-v2-h...</td>\n",
       "      <td>1037798</td>\n",
       "      <td>nDCG@10</td>\n",
       "      <td>0.370031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(TctColBert('castorini/tct_colbert-v2-h...</td>\n",
       "      <td>1037798</td>\n",
       "      <td>AP(rel=2)@100</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compose(TctColBert('castorini/tct_colbert-v2-h...</td>\n",
       "      <td>1037798</td>\n",
       "      <td>RR(rel=2)@10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compose(TctColBert('castorini/tct_colbert-v2-h...</td>\n",
       "      <td>104861</td>\n",
       "      <td>nDCG@10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compose(TctColBert('castorini/tct_colbert-v2-h...</td>\n",
       "      <td>104861</td>\n",
       "      <td>AP(rel=2)@100</td>\n",
       "      <td>0.514095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name      qid        measure  \\\n",
       "0  Compose(TctColBert('castorini/tct_colbert-v2-h...  1037798        nDCG@10   \n",
       "1  Compose(TctColBert('castorini/tct_colbert-v2-h...  1037798  AP(rel=2)@100   \n",
       "2  Compose(TctColBert('castorini/tct_colbert-v2-h...  1037798   RR(rel=2)@10   \n",
       "3  Compose(TctColBert('castorini/tct_colbert-v2-h...   104861        nDCG@10   \n",
       "4  Compose(TctColBert('castorini/tct_colbert-v2-h...   104861  AP(rel=2)@100   \n",
       "\n",
       "      value  \n",
       "0  0.370031  \n",
       "1  0.178571  \n",
       "2  1.000000  \n",
       "3  1.000000  \n",
       "4  0.514095  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_query_results = pd.read_csv('per_query_results_TCT_19.csv')\n",
    "per_query_results_2020 = pd.read_csv('per_query_results_TCT_20.csv')\n",
    "per_query_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef799d-e15c-4a84-8673-cc7f238aa550",
   "metadata": {},
   "source": [
    "### Dense Coherence-based predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b52294-ae0e-4e79-8d55-85f8bc999c86",
   "metadata": {},
   "source": [
    "Now, we show how we calculate our proposed predictors, assuming the retrieved results are obtained for each retrieval method. The results should have the following form, where query vec is the embedded representation of the query, which doc_embs corresponds to the document embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b63f8403-e0e7-4cf2-9f4f-21df09d32d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>query_vec</th>\n",
       "      <th>docno</th>\n",
       "      <th>score</th>\n",
       "      <th>docid</th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_embs</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156493</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[ 9.27510634e-02  3.18724334e-01  2.06860676e-...</td>\n",
       "      <td>2928707</td>\n",
       "      <td>81.193695</td>\n",
       "      <td>2928707</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 1.00064516e-01  1.95674345e-01  3.05602074e-...</td>\n",
       "      <td>Goldfish Only Grow to the Size of Their Enclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156493</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[ 9.27510634e-02  3.18724334e-01  2.06860676e-...</td>\n",
       "      <td>1960257</td>\n",
       "      <td>81.051800</td>\n",
       "      <td>1960257</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 8.52653831e-02  2.10671186e-01  3.27536911e-...</td>\n",
       "      <td>Goldfish Only Grow to the Size of Their Enclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156493</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[ 9.27510634e-02  3.18724334e-01  2.06860676e-...</td>\n",
       "      <td>1960255</td>\n",
       "      <td>81.024100</td>\n",
       "      <td>1960255</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 7.92131126e-02  2.00234219e-01  2.42912844e-...</td>\n",
       "      <td>Rating Newest Oldest. Best Answer: Goldfish do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156493</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[ 9.27510634e-02  3.18724334e-01  2.06860676e-...</td>\n",
       "      <td>8182162</td>\n",
       "      <td>80.989685</td>\n",
       "      <td>8182162</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 5.08242361e-02  2.15213522e-01  3.14078063e-...</td>\n",
       "      <td>Depending on his type and his environment, gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156493</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[ 9.27510634e-02  3.18724334e-01  2.06860676e-...</td>\n",
       "      <td>2612493</td>\n",
       "      <td>80.742930</td>\n",
       "      <td>2612493</td>\n",
       "      <td>4</td>\n",
       "      <td>[ 9.98763293e-02  1.84747636e-01  2.59946853e-...</td>\n",
       "      <td>In clean, uncrowded conditions in tanks or pon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid             query  \\\n",
       "0  156493  do goldfish grow   \n",
       "1  156493  do goldfish grow   \n",
       "2  156493  do goldfish grow   \n",
       "3  156493  do goldfish grow   \n",
       "4  156493  do goldfish grow   \n",
       "\n",
       "                                           query_vec    docno      score  \\\n",
       "0  [ 9.27510634e-02  3.18724334e-01  2.06860676e-...  2928707  81.193695   \n",
       "1  [ 9.27510634e-02  3.18724334e-01  2.06860676e-...  1960257  81.051800   \n",
       "2  [ 9.27510634e-02  3.18724334e-01  2.06860676e-...  1960255  81.024100   \n",
       "3  [ 9.27510634e-02  3.18724334e-01  2.06860676e-...  8182162  80.989685   \n",
       "4  [ 9.27510634e-02  3.18724334e-01  2.06860676e-...  2612493  80.742930   \n",
       "\n",
       "     docid  rank                                           doc_embs  \\\n",
       "0  2928707     0  [ 1.00064516e-01  1.95674345e-01  3.05602074e-...   \n",
       "1  1960257     1  [ 8.52653831e-02  2.10671186e-01  3.27536911e-...   \n",
       "2  1960255     2  [ 7.92131126e-02  2.00234219e-01  2.42912844e-...   \n",
       "3  8182162     3  [ 5.08242361e-02  2.15213522e-01  3.14078063e-...   \n",
       "4  2612493     4  [ 9.98763293e-02  1.84747636e-01  2.59946853e-...   \n",
       "\n",
       "                                                text  \n",
       "0  Goldfish Only Grow to the Size of Their Enclos...  \n",
       "1  Goldfish Only Grow to the Size of Their Enclos...  \n",
       "2  Rating Newest Oldest. Best Answer: Goldfish do...  \n",
       "3  Depending on his type and his environment, gol...  \n",
       "4  In clean, uncrowded conditions in tanks or pon...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list = pd.read_csv('TCT_results_19_predictor.csv')\n",
    "res_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388284ba-e689-43e7-a868-cd4605b7c52a",
   "metadata": {},
   "source": [
    "First, we define function for pairRatio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28824baa-a5bb-4b41-b45b-09b0067f13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_ratio(df_embs, lim_1, lim_2, lim_3, measure_x, per_query_res):\n",
    "    rows = []\n",
    "    \n",
    "    for qid, group in pt.tqdm(df_embs.groupby('qid'), unit='q'):\n",
    "        embs_list = torch.stack(group.doc_embs.tolist())\n",
    "        W_mat = pd.DataFrame(cosine_similarity(embs_list,dense_output=True))\n",
    "        mean_top = W_mat.iloc[0:lim_1, 0:lim_1].values.mean()\n",
    "        mean_bottom = W_mat.iloc[lim_2:lim_3, lim_2:lim_3].values.mean()\n",
    "        mean_vs = mean_top/mean_bottom\n",
    "        rows.append([qid,mean_vs])\n",
    "    df_sim = pd.DataFrame(rows, columns=['qid', 'mean_vs'])\n",
    "    merged = df_sim.merge(per_query_res, on = 'qid')\n",
    "    merged = merged[merged.measure==measure_x]\n",
    "    #corr_pearson = stats.pearsonr(merged['value'], merged['mean_vs'])[0]\n",
    "    #corr_spearman = spearmanr(merged['value'], merged['mean_vs']).correlation\n",
    "    corr_kendall = kendalltau(merged['value'], merged['mean_vs'])\n",
    "    print (corr_kendall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a9fe0-69e4-43fd-8407-337439bb1b1b",
   "metadata": {},
   "source": [
    "In the above function, lim_3 corresponds to the rank cutoff of the retrieved results, lim_1 is where the upper matrix stops, and lim_2 is where the lower matrix starts. For measure_x, replace with the metric of interest from the per_query_results, choose AP(rel=2)@100, nDCG@10, or RR(rel=2)@10. Finally, df_embs is the retrieved result list, which contains an embedded representation of each retrieved document in the list (per query) and an embedded representation of the query vectors.\n",
    "\n",
    "To test pairRatio, use the following lines. Here we use AP@100 for a cutoff at rank 100. Replace with other metrics to see what happens to NDCG@1- and MRR@10, or cutoffs by adjusting the limits. You can also use the results for TREC DL20 using per_query_results_2020. To get a different correlation metric, simply uncomment the lines for pearson and spearman's correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af64c5a7-189a-45ac-8deb-f8e7294061fd",
   "metadata": {},
   "source": [
    "Here, we demonstrate a test with a rank cutoff of 100. For a top-50 results list, the corresponding lim_1 and lim_2 will be in intervals of 5 from 5 to 35, while lim_3 would be 50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f89b03-717c-4e48-99e6-88116fc55861",
   "metadata": {},
   "source": [
    "Now, we test pairRatio as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a423ddd8-2d84-45f6-b874-4d57914e05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lim1 in [10, 20, 30, 40, 50, 60, 70, 80]:\n",
    "    print(\"lim1 %d\" % lim1)\n",
    "    for lim2 in [10, 20, 30, 40, 50, 60, 70, 80, 90]:\n",
    "        print(\"lim2 %d\" % lim2)\n",
    "        pair_ratio(combined_100, lim1, lim2, 100, 'AP(rel=2)@100', per_query_results)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99f019-c634-44e4-ab25-d3532e212e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_pair_ratio(df_embs, lim_1, lim_2, lim_3, measure_x, per_query_res):\n",
    "    rows = []\n",
    "    \n",
    "    for qid, group in pt.tqdm(df_embs.groupby('qid'), unit='q'):\n",
    "        embs_list = np.vstack(group.doc_embs.tolist())\n",
    "        query_embs = group.iloc[0].query_vec\n",
    "        score_list = group.score\n",
    "        W_mat = cosine_similarity(embs_list,dense_output=True)\n",
    "        score_exp = np.expand_dims(score_list,axis=1)\n",
    "        pair_mat = np.dot(score_exp,score_exp.T)\n",
    "        weighted_mat = W_mat@pair_mat\n",
    "        W_mat_new = pd.DataFrame(weighted_mat)\n",
    "        mean_top = W_mat_new.iloc[0:lim_1, 0:lim_1].values.mean()\n",
    "        mean_bottom = W_mat_new.iloc[lim_2:lim_3, lim_2:lim_3].values.mean()\n",
    "        mean_vs = mean_top/mean_bottom\n",
    "        rows.append([qid,mean_vs])     \n",
    "    df_sim = pd.DataFrame(rows, columns=['qid', 'mean_vs']) \n",
    "    merged = df_sim.merge(per_query_res, on = 'qid')\n",
    "    merged = merged[merged.measure==measure_x]\n",
    "    #corr_person = stats.pearsonr(merged['value'], merged['mean_vs'])[0]\n",
    "    #corr_spearman = spearmanr(merged['value'], merged['mean_vs']).correlation\n",
    "    corr_kendall = kendalltau(merged['value'], merged['mean_vs'])\n",
    "    print(corr_kendall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e10c5-8264-4494-adef-cc11e03eea68",
   "metadata": {},
   "source": [
    "To test A-pairRatio, use the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca00a1f-9b4c-43f6-9ad5-a4991c47f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lim1 in [10, 20, 30, 40, 50, 60, 70, 80]:\n",
    "    print(\"lim1 %d\" % lim1)\n",
    "    for lim2 in [10, 20, 30, 40, 50, 60, 70, 80, 90]:\n",
    "        print(\"lim2 %d\" % lim2)\n",
    "        adjusted_pair_ratio(combined_100, lim1, lim2, 100, 'AP(rel=2)@100', per_query_results)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30e0ff-62d8-4086-b0d2-591f10c301ec",
   "metadata": {},
   "source": [
    "### Top1(monoT5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14836a6d-c7d9-4a06-b58b-396e372b7214",
   "metadata": {},
   "source": [
    "On top of our dense coherence-based predictors, we propose a baseline predictor on the supervised side. Here, we provide some information on how we obtain it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab9520-5f1d-4c37-9535-13c8f2ea48ef",
   "metadata": {},
   "source": [
    "First, install the pyterrier plugin for Mono and Duo T5 from https://github.com/terrierteam/pyterrier_t5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373ff20-d5f4-459b-9068-c7f2ce0e9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade git+https://github.com/terrierteam/pyterrier_t5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06612e27-ea72-4c9d-9547-65c5e048f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_t5 import MonoT5ReRanker, DuoT5ReRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0aa40-3fcb-4691-92f2-d614661f636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monoT5 = MonoT5ReRanker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c716c5-8ff6-4b65-b552-3b8eecd86266",
   "metadata": {},
   "source": [
    "Then, assuming an example index file, we define a retrieval pipeline for the dr model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b4513-7022-4021-b432-2008e79ca97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyterrier_dr.TctColBert('castorini/tct_colbert-v2-hnp-msmarco')\n",
    "index = pyterrier_dr.NumpyIndex(\"example_index_file\", docids=True)\n",
    "retr_pipeline = model >> index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f7b50-e4da-4b53-a666-a343db08db29",
   "metadata": {},
   "source": [
    "Now, we update the pipeline by getting the document embeddings (first line). Then, in the second line, we define the cross-encoder pipeline for the proposed predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358663d-16fe-4058-859c-79eea45a3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipe = retr_pipeline >> pt.apply.doc_embs(get_embs) >> pt.text.get_text(pt.get_dataset('irds:msmarco-passage'), 'text')\n",
    "cross_encoder_pipe = new_pipe %1 >> monoT5 >> pt.apply.qpp_monot5(lambda df: df[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0194ca-0181-43b7-8e84-d8534c3301e6",
   "metadata": {},
   "source": [
    "We then transform the queries to get the final results, and we merge with the evaluation metrics to get the final correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754603d-0491-4299-b840-5ca8f1245ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "allres_t5 = cross_encoder_pipe.transform(test_topics)\n",
    "\n",
    "merged = allres_t5.merge(per_query_results)\n",
    "merged = merged[merged.measure=='AP(rel=2)@100']\n",
    "corr_kendall = kendalltau(merged['value'], merged['qpp_monot5'])\n",
    "#corr_pearson = stats.pearsonr(merged['value'], merged['qpp_monot5'])[0]\n",
    "#corr_spearman = spearmanr(merged['value'], merged['qpp_monot5']).correlation\n",
    "print(corr_kendall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a6d96-2cd8-4194-a4b7-3bb7e31b97b1",
   "metadata": {},
   "source": [
    "Simply uncomment the corresponding lines to get the pearson and spearman's correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdf73f-fa47-45b1-b54c-76798cdfc819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:genir]",
   "language": "python",
   "name": "conda-env-genir-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
